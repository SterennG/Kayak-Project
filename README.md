# KAYAK - Recommandation de destination en France

## Objectif

Recommander les meilleures destinations de vacances en France selon deux crit√®res principaux :
- **La m√©t√©o** : temp√©rature, pr√©cipitations et vent sur les 7 prochains jours.
- **Les h√¥tels** : offre h√¥teli√®re, notes des utilisateurs et description.

Le projet couvre la collecte de donn√©es (APIs & Scraping), le stockage dans un Data Lake (S3), le nettoyage et le chargement dans un Data Warehouse (RDS), et la visualisation des r√©sultats.

## Architecture
Le flux de donn√©es suit l'architecture suivante :

1. **Extraction (Extract)** :
   - **M√©t√©o** : r√©cup√©ration des donn√©es via l'API *OpenWeatherMap* et coordonn√©es GPS via *Nominatim*.
   - **H√¥tels** : scraping du site *Booking.com* √† l'aide du framework **Scrapy**.
2. **Stockage (Data Lake)** :
   - Stockage des donn√©es brutes et nettoy√©es (`.csv`) sur **AWS S3**.
3. **Chargement (Load)** :
   - Ingestion des donn√©es consolid√©es dans une base de donn√©es SQL sur **AWS RDS** (PostgreSQL).
4. **Visualisation** :
   - Cr√©ation de cartes interactives avec **Plotly** pour afficher le Top 5 des destinations et les 20 meilleurs h√¥tels.

```mermaid
graph LR
    subgraph SOURCES [Sources de Donn√©es]
        A["API OpenWeather"]
        B["API Nominatim"]
        C["Site Booking.com"]
    end

    subgraph COLLECTION [Collecte & Ingestion]
        D["Script Python<br/>(Requests)"]
        E["Scrapy Spider<br/>(Booking)"]
    end

    subgraph DATALAKE [Data Lake - AWS S3]
        F[("Fichiers CSV<br/>Bruts")]
    end

    subgraph ETL [Transformation & Warehouse]
        G["Pandas<br/>(Nettoyage & Score)"]
        H[("AWS RDS<br/>PostgreSQL")]
    end

    subgraph VIZ [Visualisation]
        I["Cartes Interactives<br/>Plotly"]
    end

    A --> D
    B --> D
    C --> E
    D --> F
    E --> F
    F --> G
    G --> H
    G --> I
    H -.-> I
```

```mermaid
graph TD

    %% ====================
    %% DOMAINES ENTREPRISE
    %% ====================
    subgraph CLIENT_APP [üß≠ Frontend / Application Client]
        VIZ["Plotly Dashboards<br/>Cartes Interactives"]
    end

    subgraph DATA_SOURCES [üåç External Data Providers]
        WEATHER_API["OpenWeather API"]
        NOMINATIM_API["Nominatim API"]
        BOOKING_WEB["Booking.com Website"]
    end

    subgraph DATA_INGESTION [üì• Data Ingestion Layer]
        INGEST_PY["Python ETL Scripts<br/>Requests + BS4"]
        %% connect sources to ingestion
        WEATHER_API --> INGEST_PY
        NOMINATIM_API --> INGEST_PY
        BOOKING_WEB --> INGEST_PY
    end

    subgraph RAW_DATALAKE [üõ¢Ô∏è AWS S3 ‚Äì Raw Zone]
        RAW_CSV["raw_data/*.csv"]
        INGEST_PY --> RAW_CSV
    end

    subgraph PROCESSING [‚öôÔ∏è Processing & Compute Layer]
        PAN["Pandas Cleaning<br/>Feature Engineering"]
        RAW_CSV --> PAN
    end

    subgraph CURATED_ZONE [üíæ AWS S3 ‚Äì Curated Zone (optionnel)]
        CURATED["curated/*.csv"]
        PAN -. optional .-> CURATED
    end

    subgraph DATA_WAREHOUSE [üèõÔ∏è AWS RDS ‚Äì PostgreSQL]
        DW_TABLE["Table: kayak_destinations"]
        PAN --> DW_TABLE
    end

    subgraph ANALYTICS [üìä Analytics Layer]
        BI["Dashboards / Exploration<br/>via SQL + Python"]
        DW_TABLE --> BI
    end

    BI --> VIZ
```